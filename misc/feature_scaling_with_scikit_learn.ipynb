{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0           1\n",
      "0  120.573  127.108268\n",
      "1  127.220  123.492931\n",
      "2  113.045  122.393120\n",
      "3  119.606  122.570836\n",
      "4  131.971  127.270743\n",
      "error 6.175637\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dat = pd.read_csv('c:\\\\Users\\\\felipe.figueiredo\\\\Documents\\\\TP-555\\\\simulations\\\\airfoil_self_noise.dat' ,sep='\\t', low_memory=False,header=None)\n",
    "\n",
    "apply_scaler = True\n",
    "\n",
    "# split into train 2/3 and test 1/3\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "n_rows = dat.shape[0]\n",
    "n_train = math.floor(0.66*n_rows)\n",
    "\n",
    "permutated_indices = rng.permutation(n_rows)\n",
    "\n",
    "train_dat = dat.loc[permutated_indices[:n_train],:]\n",
    "test_dat =  dat.loc[permutated_indices[n_train:],:]\n",
    "\n",
    "# separate the response variable (last column) from the predictor variables\n",
    "x_train = train_dat.iloc[:,1:-1]\n",
    "y_train = (train_dat.iloc[:,-1])[:, np.newaxis]\n",
    "\n",
    "x_test = test_dat.iloc[:,1:-1]\n",
    "y_test = (test_dat.iloc[:,-1])[:, np.newaxis]\n",
    "\n",
    "# train\n",
    "# fit the scaler to predictor variables and apply it afterwards\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "if apply_scaler:\n",
    "    x_train = pd.DataFrame(scaler.transform(x_train))\n",
    "\n",
    "# add constant one for the intercept parameter\n",
    "x_train = pd.concat([pd.DataFrame(np.ones(shape=(x_train.shape[0],1)),index=x_train.index),x_train],axis=1)\n",
    "\n",
    "# fit parameters of linear regression using batch gradient descent\n",
    "# Hands-On Machine Learning with Scikit-Learn & Tensorflow, page 115\n",
    "eta = 0.1 # learning rate\n",
    "n_iterations = 1000\n",
    "m = x_train.shape[0]\n",
    "theta = rng.randn(x_train.shape[1],1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = (2 / m) * x_train.T.dot(x_train.dot(theta) - y_train)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "# to apply the fitted parameters, first we have to transform the test-data in the same way\n",
    "# apply scaler\n",
    "if apply_scaler:\n",
    "    x_test = pd.DataFrame(scaler.transform(x_test))\n",
    "\n",
    "# add constant one for the intercept parameter\n",
    "x_test = pd.concat([pd.DataFrame(np.ones(shape=(x_test.shape[0],1)),index=x_test.index),x_test],axis=1)\n",
    "\n",
    "# apply fitted parameters\n",
    "y_predict =x_test.dot(theta)\n",
    "\n",
    "# compare output\n",
    "out=np.column_stack((y_test, y_predict))\n",
    "print(pd.DataFrame(out).head())\n",
    "# root mean squared error\n",
    "print(\"error %f\"% np.sqrt(np.power(y_test-y_predict,2).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
